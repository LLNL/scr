#!/usr/bin/perl -w
use strict;
use lib '@X_DATADIR@/scr';
use scr_param;
use scr_hostlist;
use Getopt::Long qw/ :config gnu_getopt ignore_case /;

# This utility scavenges files from cache to the parallel file system using pdsh.
# It checks for pdsh errors in case any nodes should be retried.

# requires: pdsh

my $bindir = "@X_BINDIR@";
my $prog = "scr_scavenge";

my $pdsh = "@PDSH_EXE@";

# TODO: need to be able to set these defaults via config settings somehow
# for now just hardcode the values
my $buf_size = 1024*1024;
my $crc_flag = "--crc";

# lookup buffer size and crc flag via scr_param
my $param = new scr_param();

my $param_buf_size = $param->get("SCR_FILE_BUF_SIZE");
if (defined $param_buf_size) {
  $buf_size = $param_buf_size;
}

my $param_crc = $param->get("SCR_CRC_ON_FLUSH");
if (defined $param_crc) {
  if ($param_crc == 0) {
    $crc_flag = "";
  }
}

my $start_time = time();

sub print_usage
{
  print "\n";
  print "  Usage:  $prog [--jobset <nodeset>] [--up <nodeset> | --down <nodeset>] --id <id> --from <dir> --to <dir>\n";
  print "\n";
  exit 1;
}

# tag output files with jobid
my $jobid = `$bindir/scr_env --jobid`;
if ($? != 0) {
  print "$prog: ERROR: Could not determine jobid.\n";
  exit 1;
}
chomp $jobid;

# read node set of job
my $jobset = `$bindir/scr_env --nodes`;
if ($? != 0) {
  print "$prog: ERROR: Could not determine nodeset.\n";
  exit 1;
}
chomp $jobset;

# read in command line arguments
my %conf = ();
$conf{nodeset_job}  = $jobset;
$conf{nodeset_up}   = undef;
$conf{nodeset_down} = undef;
$conf{dataset_id}   = undef;
$conf{dir_from}     = undef;
$conf{dir_to}       = undef;
$conf{verbose}      = 0;
my $rc = GetOptions (
   "jobset|j=s"  => \$conf{nodeset_job},
   "up|u=s"      => \$conf{nodeset_up},
   "down|d=s"    => \$conf{nodeset_down},
   "id|i=i"      => \$conf{dataset_id},
   "from|f=s"    => \$conf{dir_from},
   "to|t=s"      => \$conf{dir_to},
   "verbose|v"   => sub { $conf{verbose} = 1; },
);
if (not $rc) {
  print_usage();
}

# check that we have a nodeset for the job and directories to read from / write to
if ($conf{nodeset_job} eq "" or 
    not defined $conf{dataset_id} or
    not defined $conf{dir_from} or
    not defined $conf{dir_to})
{
  print_usage();
}

# get directories
my $cntldir   = $conf{dir_from};
my $prefixdir = $conf{dir_to};

# get nodesets
my @jobnodes  = scr_hostlist::expand($conf{nodeset_job});
my @upnodes   = ();
my @downnodes = ();
if (defined $conf{nodeset_down}) {
  @downnodes = scr_hostlist::expand($conf{nodeset_down});
  @upnodes   = scr_hostlist::diff(\@jobnodes, \@downnodes);
} elsif (defined $conf{nodeset_up}) {
  @upnodes   = scr_hostlist::expand($conf{nodeset_up});
  @downnodes = scr_hostlist::diff(\@jobnodes, \@upnodes);
} else {
  @upnodes = @jobnodes;
}

# format up and down node sets for pdsh command
my $upnodes = scr_hostlist::compress(@upnodes);
my $downnodes_spaced = join(" ", @downnodes);

# add dataset id option if one was specified
# set the dataset flag
my $dset = "$conf{dataset_id}";

# build the output filenames
my $output = "$prefixdir/.scr/scr.dataset.$dset/$prog.pdsh.o" . $jobid;
my $error  = "$prefixdir/.scr/scr.dataset.$dset/$prog.pdsh.e" . $jobid;

my $cmd = undef;

# log the start of the scavenge operation
`$bindir/scr_log_event -i $jobid -p $prefixdir -T 'SCAVENGE_START' -D $dset -S $start_time`;

# gather files via pdsh
$cmd = "$bindir/scr_copy --cntldir $cntldir --id $dset --prefix $prefixdir --buf $buf_size $crc_flag $downnodes_spaced";
print "$prog: ", scalar(localtime), "\n";
print "$prog: $pdsh -f 256 -S -w '$upnodes' \"$cmd\" >$output 2>$error\n";
             `$pdsh -f 256 -S -w '$upnodes'  "$cmd"  >$output 2>$error`;

# print pdsh output to screen
if ($conf{verbose}) {
  if (-r $output) {
    print "$prog: stdout: cat $output\n";
    print `cat $output`;
    print "\n";
  }

  if (-r $error) {
    print "$prog: stderr: cat $error\n";
    print `cat $error`;
    print "\n";
  }
}

# TODO: if we knew the total bytes, we could register a transfer here in addition to an event
# get a timestamp for logging timing values
my $end_time = time();
my $diff_time = $end_time - $start_time;
`$bindir/scr_log_event -i $jobid -p $prefixdir -T 'SCAVENGE_END' -D $dset -S $start_time -L $diff_time`;

exit 0;
