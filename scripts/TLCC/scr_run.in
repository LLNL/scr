#!/bin/bash

# requires: srun

# Print usage
if [ -z "$1" ]; then
    echo USAGE:
    echo "scr_srun [srun args] [-rc|--run-cmd=<run_command>] [-rs|--restart-cmd=<restart_command>] [srun args]"
    echo "<run_command>: The command to run when no restart file is present"
    echo "<restart_command>: The command to run when a restart file is present"
    echo ""
    echo "The invoked command will be \`srun [srun_args] [run_command]\` when no restart file is present"
    echo "The invoked command will be \`srun [srun_args] [restart_command]\` when a restart file is present"
    echo "If the string \"SCR_CKPT_NAME\" appears in the restart command, it will be replace by the name "
    echo "presented to SCR when the most recent checkpoint was written."
    echo ""
    echo "If no restart command is specified, the run command will always be used"
    echo "If no commands are specified, the srun arguments will be passed directly to srun in all circumstances"
    echo "If no run command is specified, but a restart command is specified,"
    echo "then the restart command will be appended to the srun arguments when a restart file is present."
    exit 0
fi

# capture restart and run commands if specified
srun_args=""
while [ ${1:+x} ]; do
    case $1 in
        --restart-cmd|-rs)
            restart_cmd=$2
            shift 2 ;;
        --run-cmd|-rc)
            run_cmd=$2
            shift 2 ;;
        --restart-cmd=*|-rs=*)
            restart_cmd=${1#*=}
            if [ -z "$restart_cmd" ]; then shift; restart_cmd=$1; fi
            shift ;;
        --run-cmd=*|-rc=*)
            run_cmd=${1#*=}
            if [ -z "$run_cmd" ]; then shift; run_cmd=$1; fi
            shift ;;
        *)
            srun_args="$srun_args $1"
            shift ;;
    esac
done

# if SCR is disabled, just do a normal run and exit
if [ "$SCR_ENABLE" == "0" ] ; then
  srun $srun_args $run_cmd
  exit $?
fi

# turn on verbosity
if [ -n "$SCR_DEBUG" ]; then
  if [ $SCR_DEBUG -gt 0 ] ; then
    set -x
  fi
fi

prog=scr_srun

libdir="@X_LIBDIR@"
bindir="@X_BINDIR@"

# make a record of start time
timestamp=`date`
echo "$prog: Started: $timestamp"

# check that we have runtime dependencies
$bindir/scr_test_runtime
if [ $? -ne 0 ] ; then
  echo "$prog: exit code: 1"
  exit 1
fi

# TODO: if not in job allocation, bail out

jobid=`$bindir/scr_env --jobid`

# TODO: check that we have a valid jobid and bail if not

# get the nodeset of this job
if [ -z "$SCR_NODELIST" ] ; then
  nodelist=`$bindir/scr_env --nodes`
  if [ $? -eq 0 ] ; then
    SCR_NODELIST=$nodelist
  fi
fi
if [ -z "$SCR_NODELIST" ] ; then
  echo "$prog: ERROR: Could not identify nodeset"
  exit 1
fi
export SCR_NODELIST

# get prefix directory
prefix=`$bindir/scr_prefix`

use_scr_watchdog=0
if [ "$SCR_WATCHDOG" == "1" ] ; then
  use_scr_watchdog=1
fi

# get the control directory
cntldir=`$bindir/scr_list_dir control`
if [ $? -ne 0 ] ; then
  echo "$prog: ERROR: Invalid control directory $cntldir."
  exit 1
fi

# NOP srun to force every node to run prolog to delete files from cache
# TODO: remove this if admins find a better place to clear cache
srun /bin/hostname > /dev/null

# make a record of time prerun is started
timestamp=`date`
echo "$prog: prerun: $timestamp"

# prepare checkpoint cache
$bindir/scr_prerun -p $prefix
if [ $? -ne 0 ] ; then
  echo "$prog: ERROR: Command failed: scr_prerun -p $prefix"
  exit 1
fi

# start background scr_transfer processes (1 per node) if async flush is enabled
if [ "$SCR_FLUSH_ASYNC" == "1" ] ; then
  nnodes=`$bindir/scr_glob_hosts --count --hosts $SCR_NODELIST`
  srun -W 0 -n${nnodes} -N${nnodes} $bindir/scr_transfer $cntldir/transfer.scrinfo &
fi

# enter the run loop
down_nodes=""
attempts=0
runs=${SCR_RETRIES:-0}
runs=$(($runs + 1))
runs=${SCR_RUNS:-$runs}
while [ 1 ] ; do
  # once we mark a node as bad, leave it as bad (even if it comes back healthy)
  # TODO: This hacks around the problem of accidentally deleting a checkpoint set during distribute
  #       when a relaunch lands on previously down nodes, which are healthy again.
  #       A better way would be to remember the last set used, or to provide a utility to run on *all*
  #       nodes to distribute files (also useful for defragging the machine) -- for now this works.
  keep_down=""
  if [ "$down_nodes" != "" ] ; then
    keep_down="--down $down_nodes"
  fi

  # if this is our first run, check that the free space on the drive meets requirement
  # (make sure data from job of previous user was cleaned up ok)
  # otherwise, we'll just check the total capacity
  free_flag=""
  if [ $attempts -eq 0 ] ; then
    free_flag="--free"
  fi

  # are there enough nodes to continue?
  exclude=""
  down_nodes=`$bindir/scr_list_down_nodes $free_flag $keep_down`
  if [ "$down_nodes" != "" ] ; then
    # print the reason for the down nodes, and log them
    $bindir/scr_list_down_nodes $free_flag $keep_down --log --reason --secs 0

    # if this is the first run, we hit down nodes right off the bat, make a record of them
    if [ $attempts -eq 0 ] ; then
      start_secs=`date +%s`
      echo "SCR: Failed node detected: JOBID=$jobid ATTEMPT=$attempts TIME=$start_secs NNODES=-1 RUNTIME=0 FAILED=$down_nodes"
    fi

    # determine how many nodes are needed:
    #   if SCR_MIN_NODES is set, use that
    #   otherwise, use value in nodes file if one exists
    #   otherwise, assume we need all nodes in the allocation
    # to start, assume we need all nodes in the allocation
    num_needed=`$bindir/scr_glob_hosts --count --hosts $SCR_NODELIST`
    if [ -n "$SCR_MIN_NODES" ]  ; then
      # if SCR_MIN_NODES is set, use that
      num_needed=$SCR_MIN_NODES
    else
      # try to lookup the number of nodes used in the last run
      num_needed_env=`$bindir/scr_env --prefix $prefix --runnodes`
      if [ $? -eq 0 ] ; then
        if [ $num_needed_env -gt 0 ] ; then
          # if the command worked, and the number is something larger than 0, go with that
          num_needed=$num_needed_env
        fi
      fi
    fi

    # check that we have enough nodes left to run the job after excluding all down nodes
    num_left=`$bindir/scr_glob_hosts --count --minus $SCR_NODELIST:$down_nodes`
    if [ $num_left -lt $num_needed ] ; then
      echo "$prog: (Nodes remaining=$num_left) < (Nodes needed=$num_needed), ending run."
      break
    fi

    # all checks pass, exclude the down nodes and continue
    exclude="--exclude $down_nodes"
  fi

  # make a record of when each run is started
  attempts=$(($attempts + 1))
  timestamp=`date`
  echo "$prog: RUN $attempts: $timestamp"

  launch_cmd="$srun_args $run_cmd"
  if [ ${restart_cmd:+x} ]; then
      restart_name=`srun $srun_args $bindir/scr_have_restart`
      if [ ${restart_name:+x} ]; then
          my_restart_cmd=`echo $restart_cmd | sed "s#SCR_CKPT_NAME#${restart_name}#g"`
          launch_cmd="$srun_args $my_restart_cmd"
      fi
  fi

  # launch the job, make sure we include the script node and exclude down nodes
  start_secs=`date +%s`
  $bindir/scr_log_event -T "RUN STARTED" -N "Job=$jobid, Run=$attempts" -S $start_secs

  if [ $use_scr_watchdog -eq 0 ]; then
     srun $exclude $launch_cmd
  else
    echo "$prog: Attempting to start watchdog process."
     # need to get job step id of the srun command
     srun $exclude $launch_cmd &
     srun_pid=$!;
     sleep 10; # sleep a bit to wait for the job to show up in squeue
     echo "$bindir/scr_get_jobstep_id $srun_pid";
     jobstepid=`$bindir/scr_get_jobstep_id $srun_pid`;
     # then start the watchdog  if we got a valid job step id
     if [ $jobstepid != "-1" ]; then
         $bindir/scr_watchdog --dir $prefix --jobStepId $jobstepid &
         watchdog_pid=$!;
         echo "$prog: Started watchdog process with PID $watchdog_pid."
     else
        echo "$prog: ERROR: Unable to start scr_watchdog because couldn't get job step id."
        watchdog_pid=-1;
     fi
     wait $srun_pid;
  fi

  end_secs=`date +%s`
  run_secs=$(($end_secs - $start_secs))

  # check for and log any down nodes
  $bindir/scr_list_down_nodes $keep_down --log --reason --secs $run_secs

  # log stats on the latest run attempt
  $bindir/scr_log_event -T "RUN ENDED" -N "Job=$jobid, Run=$attempts" -S $end_secs -L $run_secs

  # any retry attempts left?
  if [ $runs -gt -1 ] ; then
    runs=$(($runs - 1))
    if [ $runs -le 0 ] ; then
      echo "$prog: \$SCR_RUNS exhausted, ending run."
      break
    fi
  fi

  # is there a halt condition instructing us to stop?
  $bindir/scr_retries_halt --dir $prefix;
  if [ $? == 0 ] ; then
    echo "$prog: Halt condition detected, ending run."
    break
  fi

  # give nodes a chance to clean up
  sleep 60

  # check for halt condition again after sleep
  $bindir/scr_retries_halt --dir $prefix;
  if [ $? == 0 ] ; then
    echo "$prog: Halt condition detected, ending run."
    break
  fi
done

# stop scr_transfer processes before we attempt to scavenge
if [ "$SCR_FLUSH_ASYNC" == "1" ] ; then
  # TODO: this doesn't currently do anything
  $bindir/scr_halt --immediate $prefix
fi

# make a record of time postrun is started
timestamp=`date`
echo "$prog: postrun: $timestamp"

# scavenge files from cache to parallel file system
$bindir/scr_postrun -p $prefix
if [ $? -ne 0 ] ; then
  echo "$prog: ERROR: Command failed: scr_postrun -p $prefix"
fi

# kill the watchdog process if it is running
if [ $use_scr_watchdog -eq 1 ] && [ $watchdog_pid -ne -1 ]; then
  echo "$kill -n KILL $watchdog_pid";
  kill -n KILL $watchdog_pid;
fi

# make a record of end time
timestamp=`date`
echo "$prog: Ended: $timestamp"
