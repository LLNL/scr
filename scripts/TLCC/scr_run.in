#!/bin/bash

# requires: srun

# if SCR is disabled, just do a normal srun and exit
if [ "$SCR_ENABLE" == "0" ] ; then
  srun "$@"
  exit $?
fi

# turn on verbosity
if [ -n "$SCR_DEBUG" ]; then
  if [ $SCR_DEBUG -gt 0 ] ; then
    set -x
  fi
fi

prog=scr_srun

libdir="@X_LIBDIR@"
bindir="@X_BINDIR@"

# make a record of start time
timestamp=`date`
echo "$prog: Started: $timestamp"

# check that we have runtime dependencies
$bindir/scr_test_runtime
if [ $? -ne 0 ] ; then
  echo "$prog: exit code: 1"
  exit 1
fi

# TODO: if not in job allocation, bail out

jobid=`$bindir/scr_env --jobid`

# TODO: check that we have a valid jobid and bail if not

# get the nodeset of this job
if [ -z "$SCR_NODELIST" ] ; then
  nodelist=`$bindir/scr_env --nodes`
  if [ $? -eq 0 ] ; then
    SCR_NODELIST=$nodelist
  fi
fi
if [ -z "$SCR_NODELIST" ] ; then
  echo "$prog: ERROR: Could not identify nodeset"
  exit 1
fi
export SCR_NODELIST

# if SCR_PREFIX is not set, use the current working directory
if [ -z "$SCR_PREFIX" ] ; then
  SCR_PREFIX=`pwd`
fi
# if SCR_PREFIX is still not set, bail out
if [ -z "$SCR_PREFIX" ] ; then
  echo "$prog: ERROR: Must set \$SCR_PREFIX to prefix directory which contains checkpoint directories."
  exit 1
fi
prefix=$SCR_PREFIX

# check that this script is running on a node in the job's allocated nodeset
script_node=`hostname`
intersection=`$bindir/scr_glob_hosts -i $script_node:$SCR_NODELIST`
if [ -z "$intersection" ] ; then
  echo "$prog: ERROR: scr_run is executing on $script_node, which is not part of the job's nodeset $SCR_NODELIST."
  exit 1
fi

# get the control directory
cntldir=`$bindir/scr_cntl_dir`
if [ $? -ne 0 ] ; then
  echo "$prog: ERROR: Invalid control directory $cntldir."
  exit 1
fi

# NOP srun to force every node to run prolog to delete files from cache
# TODO: remove this if admins find a better place to clear cache
srun /bin/hostname > /dev/null

# make a record of time prerun is started
timestamp=`date`
echo "$prog: prerun: $timestamp"

# prepare checkpoint cache
$bindir/scr_prerun -p $prefix
if [ $? -ne 0 ] ; then
  echo "$prog: ERROR: Command failed: scr_prerun -p $prefix"
  exit 1
fi

# start background scr_transfer processes (1 per node) if async flush is enabled
if [ "$SCR_FLUSH_ASYNC" == "1" ] ; then
  nnodes=`$bindir/scr_glob_hosts -c -h $SCR_NODELIST`
  srun -W 0 -n${nnodes} -N${nnodes} $bindir/scr_transfer $cntldir/transfer.scrinfo &
fi

# enter the run loop
down_nodes=""
attempts=0
runs=${SCR_RETRIES:-0}
runs=$(($runs + 1))
runs=${SCR_RUNS:-$runs}
while [ 1 ] ; do
  # once we mark a node as bad, leave it as bad (even if it comes back healthy)
  # TODO: This hacks around the problem of accidentally deleting a checkpoint set during distribute
  #       when a relaunch lands on previously down nodes, which are healthy again.
  #       A better way would be to remember the last set used, or to provide a utility to run on *all*
  #       nodes to distribute files (also useful for defragging the machine) -- for now this works.
  keep_down=""
  if [ "$down_nodes" != "" ] ; then
    keep_down="--down $down_nodes"
  fi

  # if this is our first run, check that the free space on the drive meets requirement
  # (make sure data from job of previous user was cleaned up ok)
  # otherwise, we'll just check the total capacity
  free_flag=""
  if [ $attempts -eq 0 ] ; then
    free_flag="--free"
  fi

  # are there enough nodes to continue?
  exclude=""
  down_nodes=`$bindir/scr_list_down_nodes $free_flag $keep_down`
  if [ "$down_nodes" != "" ] ; then
    # print the reason for the down nodes, and log them
    $bindir/scr_list_down_nodes $free_flag $keep_down --log --reason --secs 0

    # if this is the first run, we hit down nodes right off the bat, make a record of them
    if [ $attempts -eq 0 ] ; then
      start_secs=`date +%s`
      echo "SCR: Failed node detected: JOBID=$jobid ATTEMPT=$attempts TIME=$start_secs NNODES=-1 RUNTIME=0 FAILED=$down_nodes"
    fi

    # determine how many nodes are needed:
    #   if SCR_MIN_NODES is set, use that
    #   otherwise, use value in nodes file if one exists
    #   otherwise, assume we need all nodes in the allocation
    # to start, assume we need all nodes in the allocation
    num_needed=`$bindir/scr_glob_hosts -c -h $SCR_NODELIST`
    if [ -n "$SCR_MIN_NODES" ]  ; then
      # if SCR_MIN_NODES is set, use that
      num_needed=$SCR_MIN_NODES
    else
      # try to lookup the number of nodes used in the last run
      num_needed_env=`$bindir/scr_env --prefix $prefix --runnodes`
      if [ $? -eq 0 ] ; then
        if [ $num_needed_env -gt 0 ] ; then
          # if the command worked, and the number is something larger than 0, go with that
          num_needed=$num_needed_env
        fi
      fi
    fi

    # check that we have enough nodes left to run the job after excluding all down nodes
    num_left=`$bindir/scr_glob_hosts -c -m $SCR_NODELIST:$down_nodes`
    if [ $num_left -lt $num_needed ] ; then
      echo "$prog: (Nodes remaining=$num_left) < (Nodes needed=$num_needed), ending run."
      break
    fi

    # check that we don't exclude the node this script is running on
    intersection=`$bindir/scr_glob_hosts -i $script_node:$down_nodes`
    if [ -n "$intersection" ] ; then
      echo "$prog: Script node $script_node is in the exclude set on retry $down_nodes, ending run."
      break
    fi

    # all checks pass, exclude the down nodes and continue
    exclude="--exclude $down_nodes"
  fi

  # make a record of when each srun is started
  attempts=$(($attempts + 1))
  timestamp=`date`
  echo "$prog: RUN $attempts: $timestamp"

  # launch the job, make sure we include the script node and exclude down nodes
  start_secs=`date +%s`
  $bindir/scr_log_event -T "RUN STARTED" -N "Job=$jobid, Run=$attempts" -S $start_secs
  if [ -n "$SCR_CHECKPOINT_PATTERN" ] ; then export LD_PRELOAD="$libdir/libscr_interpose.so" ; fi
  srun --nodelist $script_node $exclude "$@"
  if [ -n "$SCR_CHECKPOINT_PATTERN" ] ; then unset LD_PRELOAD ; fi
  end_secs=`date +%s`
  run_secs=$(($end_secs - $start_secs))

  # check for and log any down nodes
  $bindir/scr_list_down_nodes $keep_down --log --reason --secs $run_secs

  # log stats on the latest run attempt
  $bindir/scr_log_event -T "RUN ENDED" -N "Job=$jobid, Run=$attempts" -S $end_secs -D $run_secs

  # any retry attempts left?
  if [ $runs -gt -1 ] ; then
    runs=$(($runs - 1))
    if [ $runs -le 0 ] ; then
      echo "$prog: \$SCR_RUNS exhausted, ending run."
      break
    fi
  fi

  # TODO: this assumes srun is running where rank 0 runs
  # is there a halt condition instructing us to stop?
  $bindir/scr_retries_halt;
  if [ $? == 0 ] ; then
    echo "$prog: Halt condition detected, ending run."
    break
  fi

  # give nodes a chance to clean up
  sleep 60

  # check for halt condition again after sleep
  $bindir/scr_retries_halt;
  if [ $? == 0 ] ; then
    echo "$prog: Halt condition detected, ending run."
    break
  fi
done

# stop scr_transfer processes before we attempt to scavenge
if [ "$SCR_FLUSH_ASYNC" == "1" ] ; then
  $bindir/scr_halt --immediate
fi

# make a record of time postsrun is started
timestamp=`date`
echo "$prog: postrun: $timestamp"

# scavenge files from cache to parallel file system
$bindir/scr_postrun -p $prefix
if [ $? -ne 0 ] ; then
  echo "$prog: ERROR: Command failed: scr_postrun -p $prefix"
fi

# make a record of end time
timestamp=`date`
echo "$prog: Ended: $timestamp"
