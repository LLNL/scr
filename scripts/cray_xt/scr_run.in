#!/bin/bash

# requires: aprun

# Print usage
if [ -z $1 ]; then
    echo USAGE:
    echo "scr_aprun [aprun args] [-rc|--run-cmd=<run_command>] [-rs|--restart-cmd=<restart_command>] [aprun args]"
    echo "<run_command>: The command to run when no restart file is present"
    echo "<restart_command>: The command to run when a restart file is present"
    echo ""
    echo "The invoked command will be \`aprun [aprun_args] [run_command]\` when no restart file is present"
    echo "The invoked command will be \`aprun [aprun_args] [restart_command]\` when a restart file is present"
    echo "If the string \"SCR_CKPT_NAME\" appears in the restart command, it will be replace by the name "
    echo "presented to SCR when the most recent checkpoint was written."
    echo ""
    echo "If no restart command is specified, the run command will always be used"
    echo "If no commands are specified, the aprun arguments will be passed directly to aprun in all circumstances"
    echo "If no run command is specified, but a restart command is specified,"
    echo "then the restart command will be appended to the aprun arguments when a restart file is present."
    exit 0
fi

# capture restart and run commands if specified
aprun_args=""
while [ ${1+x} ]; do
    case $1 in
        --restart-cmd|-rs)
            restart_cmd=$1
            shift 2 ;;
        --run-cmd|-rc)
            run_cmd=$2
            shift 2 ;;
        --restart-cmd=*|-rs=*)
            restart_cmd=${1#*=}
            if [ -z $restart_cmd ]; then shift; restart_cmd=$1; fi
            shift ;;
        --run-cmd=*|-rc=*)
            run_cmd=${1#*=}
            if [ -z $run_cmd ]; then shift; run_cmd=$1; fi
            shift ;;
        *)
            aprun_args="$aprun_args $1"
            shift ;;
    esac
done

# if SCR is disabled, just do a normal run and exit
if [ "$SCR_ENABLE" == "0" ] ; then
  aprun $aprun_args $run_cmd
  exit $?
fi

# turn on verbosity
if [ -n "$SCR_DEBUG" ]; then
  if [ $SCR_DEBUG -gt 0 ] ; then
    set -x
  fi
fi

prog=scr_run

libdir="@X_LIBDIR@"
bindir="@X_BINDIR@"

# make a record of start time
timestamp=`date`
echo "$prog: Started: $timestamp"

# check that we have runtime dependencies
$bindir/scr_test_runtime
if [ $? -ne 0 ] ; then
  echo "$prog: exit code: 1"
  exit 1
fi

# TODO: if not in job allocation, bail out

jobid=`$bindir/scr_env --jobid`

# TODO: check that we have a valid jobid and bail if not

# get the nodeset of this job
if [ -z "$SCR_NODELIST" ] ; then
  nodelist=`$bindir/scr_env --nodes`
  if [ $? -eq 0 ] ; then
    SCR_NODELIST=$nodelist
  fi
fi
if [ -z "$SCR_NODELIST" ] ; then
  echo "$prog: ERROR: Could not identify nodeset"
  exit 1
fi
export SCR_NODELIST

# get prefix directory
prefix=`$bindir/scr_prefix`

use_scr_watchdog=0
if [ "$SCR_WATCHDOG" == "1" ] ; then
  use_scr_watchdog=1
fi

# normally we would check that this script is running on a node in the job's
# allocated nodeset, but on crays, this script runs on MOM node
script_node=`hostname`
#intersection=`$bindir/scr_glob_hosts --intersection $script_node:$SCR_NODELIST`
#if [ -z "$intersection" ] ; then
  #echo "$prog: ERROR: scr_run is executing on $script_node, which is not part of the job's nodeset $SCR_NODELIST."
  #exit 1
#fi

# get the control directory
cntldir=`$bindir/scr_list_dir control`
if [ $? -ne 0 ] ; then
  echo "$prog: ERROR: Invalid control directory $cntldir."
  exit 1
fi

# NOP aprun to force every node to run prolog to delete files from cache
# TODO: remove this if admins find a better place to clear cache
aprun /bin/hostname > /dev/null

# make a record of time prerun is started
timestamp=`date`
echo "$prog: prerun: $timestamp"

# prepare checkpoint cache
$bindir/scr_prerun -p $prefix
if [ $? -ne 0 ] ; then
  echo "$prog: ERROR: Command failed: scr_prerun -p $prefix"
  exit 1
fi

# start background scr_transfer processes (1 per node) if async flush is enabled
#if [ "$SCR_FLUSH_ASYNC" == "1" ] ; then
#  nnodes=`$bindir/scr_glob_hosts --count --hosts $SCR_NODELIST`
#  # original srun command to emulate
#  #srun -W 0 -n${nnodes} -N${nnodes} $bindir/scr_transfer $cntldir/transfer.scrinfo &
#  # aprun doesn't appear to have an equivalent to -W  (wait indefinitely after rank
#  # 0 terminates)
#  aprun -n${nnodes} -N 1 $bindir/scr_transfer $cntldir/transfer.scrinfo &
#fi

# Parse checkjob to get the used and maximum job time and compute the end time
# of the allocation in seconds since the epoch.
to_seconds () {
	   h=`echo $1 | cut -d ":" -f 1`
	   m=`echo $1 | cut -d ":" -f 2`
	   s=`echo $1 | cut -d ":" -f 3`
	   echo $((10#$h * 3600 + 10#$m * 60 + 10#$s))
}
raw_used_time=`checkjob $PBS_JOBID | grep WallTime: | sed "s/ \+/ /g"| cut -d " " -f 2`
raw_max_time=`checkjob $PBS_JOBID | grep WallTime: | sed "s/ \+/ /g"| cut -d " " -f 4`
used_time=`to_seconds $raw_used_time`
max_time=`to_seconds $raw_max_time`
current_time=`date +%s`
export SCR_END_TIME=$(($current_time + $max_time - $used_time))

# enter the run loop
down_nodes=""
attempts=0
runs=${SCR_RETRIES:-0}
runs=$(($runs + 1))
runs=${SCR_RUNS:-$runs}
while [ 1 ] ; do
  # once we mark a node as bad, leave it as bad (even if it comes back healthy)
  # TODO: This hacks around the problem of accidentally deleting a checkpoint set during distribute
  #       when a relaunch lands on previously down nodes, which are healthy again.
  #       A better way would be to remember the last set used, or to provide a utility to run on *all*
  #       nodes to distribute files (also useful for defragging the machine) -- for now this works.
  keep_down=""
  if [ "$down_nodes" != "" ] ; then
    keep_down="--down $down_nodes"
  fi

  # if this is our first run, check that the free space on the drive meets requirement
  # (make sure data from job of previous user was cleaned up ok)
  # otherwise, we'll just check the total capacity
  free_flag=""
  if [ $attempts -eq 0 ] ; then
    free_flag="--free"
  fi

  # are there enough nodes to continue?
  exclude=""
  down_nodes=`$bindir/scr_list_down_nodes $free_flag $keep_down`
  if [ "$down_nodes" != "" ] ; then
    # print the reason for the down nodes, and log them
    $bindir/scr_list_down_nodes $free_flag $keep_down --log --reason --secs 0

    # if this is the first run, we hit down nodes right off the bat, make a record of them
    if [ $attempts -eq 0 ] ; then
      start_secs=`date +%s`
      echo "SCR: Failed node detected: JOBID=$jobid ATTEMPT=$attempts TIME=$start_secs NNODES=-1 RUNTIME=0 FAILED=$down_nodes"
    fi

    # determine how many nodes are needed:
    #   if SCR_MIN_NODES is set, use that
    #   otherwise, use value in nodes file if one exists
    #   otherwise, assume we need all nodes in the allocation
    # to start, assume we need all nodes in the allocation
    num_needed=`$bindir/scr_glob_hosts --count --hosts $SCR_NODELIST`
    if [ -n "$SCR_MIN_NODES" ]  ; then
      # if SCR_MIN_NODES is set, use that
      num_needed=$SCR_MIN_NODES
    else
      # try to lookup the number of nodes used in the last run
      num_needed_env=`$bindir/scr_env --prefix $prefix --runnodes`
      if [ $? -eq 0 ] ; then
        if [ $num_needed_env -gt 0 ] ; then
          # if the command worked, and the number is something larger than 0, go with that
          num_needed=$num_needed_env
        fi
      fi
    fi

    # check that we have enough nodes left to run the job after excluding all down nodes
    num_left=`$bindir/scr_glob_hosts --count --minus $SCR_NODELIST:$down_nodes`
    if [ $num_left -lt $num_needed ] ; then
      echo "$prog: (Nodes remaining=$num_left) < (Nodes needed=$num_needed), ending run."
      break
    fi

    # check that we don't exclude the node this script is running on
    intersection=`$bindir/scr_glob_hosts --intersection $script_node:$down_nodes`
    if [ -n "$intersection" ] ; then
      echo "$prog: Script node $script_node is in the exclude set on retry $down_nodes, ending run."
      break
    fi

    # all checks pass, exclude the down nodes and continue
    exclude="--exclude $down_nodes"
  fi

  # make a record of when each run is started
  attempts=$(($attempts + 1))
  timestamp=`date`
  echo "$prog: RUN $attempts: $timestamp"

  # launch the job, make sure we include the script node and exclude down nodes
  start_secs=`date +%s`
  $bindir/scr_log_event -T "RUN STARTED" -N "Job=$jobid, Run=$attempts" -S $start_secs

  #original srun command to emulate
  #srun --nodelist $script_node $exclude "$@"
  # aprun doesn't appear to have an equivalent to --exclude
  # on cray_xt, batch script doesn't run on the same node as rank 0 (service node)
  upnodes=""
  if [ -n "$down_nodes" ]; then
     upnodes=`$bindir/scr_glob_hosts --minus $SCR_NODELIST:$down_nodes`
  else
     upnodes=$SCR_NODELIST
  fi
  # strip off the brackets around the node names because aprun doesn't like them
  tmpupnodes=${upnodes%]}
  tmpupnodes=${tmpupnodes:1}

  launch_cmd="$aprun_args $run_cmd"
  if [ ${restart_cmd+x} ]; then
      restart_name=`srun $srun_args scr_have_restart`
      if [ ${restart_name+x} ]; then
          restart_cmd=`echo $restart_cmd | sed "s#SCR_CKPT_NAME#${restart_name}#"`
          launch_cmd="$aprun_args $restart_cmd"
      fi
  fi

  if [ $use_scr_watchdog -eq 0 ]; then
     aprun -L $tmpupnodes $launch_cmd
  else
    echo "$prog: Attempting to start watchdog process."
    # need to get apid of the aprun command
     aprun -L $tmpupnodes $launch_cmd &
     aprun_pid=$!;
     sleep 10; # sleep a bit to wait for the job to show up in apstat
     echo "$bindir/scr_get_jobstep_id $aprun_pid";
     apid=`$bindir/scr_get_jobstep_id $aprun_pid`;
     # then start the watchdog  if we got a valid apid
     if [ $apid != "-1" ]; then
         $bindir/scr_watchdog --dir $prefix --jobStepId $apid &
         watchdog_pid=$!
         echo "$prog: Started watchdog process with PID $watchdog_pid."
     else
        echo "$prog: ERROR: Unable to start scr_watchdog because couldn't get apid of jobstep."
        watchdog_pid=-1;
     fi
     wait $aprun_pid;
  fi

  end_secs=`date +%s`
  run_secs=$(($end_secs - $start_secs))

  # check for and log any down nodes
  $bindir/scr_list_down_nodes $keep_down --log --reason --secs $run_secs

  # log stats on the latest run attempt
  $bindir/scr_log_event -T "RUN ENDED" -N "Job=$jobid, Run=$attempts" -S $end_secs -D $run_secs

  # any retry attempts left?
  if [ $runs -gt -1 ] ; then
    runs=$(($runs - 1))
    if [ $runs -le 0 ] ; then
      echo "$prog: \$SCR_RUNS exhausted, ending run."
      break
    fi
  fi

  # is there a halt condition instructing us to stop?
  $bindir/scr_retries_halt --dir $prefix;
  if [ $? == 0 ] ; then
    echo "$prog: Halt condition detected, ending run."
    break
  fi

  # give nodes a chance to clean up
  sleep 60

  # check for halt condition again after sleep
  $bindir/scr_retries_halt --dir $prefix;
  if [ $? == 0 ] ; then
    echo "$prog: Halt condition detected, ending run."
    break
  fi
done

# stop scr_transfer processes before we attempt to scavenge
#if [ "$SCR_FLUSH_ASYNC" == "1" ] ; then
#  # TODO: this doesn't currently do anything
#  $bindir/scr_halt --immediate $prefix
#fi

# make a record of time postrun is started
timestamp=`date`
echo "$prog: postrun: $timestamp"

# scavenge files from cache to parallel file system
$bindir/scr_postrun -p $prefix
if [ $? -ne 0 ] ; then
  echo "$prog: ERROR: Command failed: scr_postrun -p $prefix"
fi

# kill the check time remaining program
echo "$prog: kill -n KILL $check_time_pid";
kill -n KILL $check_time_pid;

# kill the watchdog process if it is running
if [ $use_scr_watchdog -eq 1 ] && [ $watchdog_pid -ne -1 ]; then
  echo "$kill -n KILL $watchdog_pid";
  kill -n KILL $watchdog_pid;
fi

# make a record of end time
timestamp=`date`
echo "$prog: Ended: $timestamp"
